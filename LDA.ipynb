{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from ast import literal_eval\n",
    "\n",
    "# import data\n",
    "df = pd.read_csv('data/nvidia_articles.csv', converters={'content': literal_eval,\n",
    "                                                         'stemmed_content': literal_eval,\n",
    "                                                         'lemmatized_content': literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "col = 'lemmatized_content'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time',\n",
       " 'technology',\n",
       " 'zacks',\n",
       " 'price',\n",
       " 'buy',\n",
       " 'earnings',\n",
       " 'billion',\n",
       " 'quarter',\n",
       " 'high',\n",
       " 'growth',\n",
       " 'u',\n",
       " 'strong',\n",
       " 'nyse',\n",
       " 'last',\n",
       " 'see',\n",
       " 'investor',\n",
       " 'report',\n",
       " 'one',\n",
       " 'also',\n",
       " 'revenue',\n",
       " 'expected',\n",
       " 'new']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all unique words in corpus\n",
    "all_content = list(df[col])\n",
    "all_words = [item for row in all_content for item in row] # flatten list\n",
    "unique_words = set(all_words)\n",
    "\n",
    "# find corpus stopwords that appear in more than specified percentage of articles\n",
    "threshold = 0.50\n",
    "\n",
    "set_content = df[col].apply(set)\n",
    "n_articles = len(df)\n",
    "corpus_stopwords = []\n",
    "for word in unique_words:\n",
    "    perc_articles = set_content.apply(lambda x: word in x).sum() / n_articles\n",
    "    if perc_articles > threshold:\n",
    "        corpus_stopwords.append(word)\n",
    "\n",
    "corpus_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove corpus stopwords\n",
    "df[col] = df[col].apply(lambda x: [word for word in x if word not in corpus_stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map words to integer ids\n",
    "id2word = gensim.corpora.Dictionary(df[col])\n",
    "\n",
    "# create a bag of words representation of the data\n",
    "bow = [id2word.doc2bow(doc) for doc in df[col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# number of topics\n",
    "n_topics = 20\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=bow, id2word=id2word, num_topics=n_topics, eta=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.002*\"estimate\" + 0.001*\"rank\" + 0.001*\"million\" + 0.001*\"p\" + 0.001*\"week\" + 0.001*\"inc\" + 0.001*\"investment\" + 0.001*\"day\" + 0.001*\"index\" + 0.001*\"trade\"\n",
      "Topic: 1 \n",
      "Words: 0.002*\"estimate\" + 0.001*\"rank\" + 0.001*\"week\" + 0.001*\"million\" + 0.001*\"day\" + 0.001*\"p\" + 0.001*\"inc\" + 0.001*\"investment\" + 0.001*\"trade\" + 0.001*\"industry\"\n",
      "Topic: 2 \n",
      "Words: 0.001*\"inc\" + 0.001*\"estimate\" + 0.001*\"million\" + 0.001*\"rank\" + 0.001*\"day\" + 0.001*\"week\" + 0.001*\"trade\" + 0.001*\"data\" + 0.001*\"investment\" + 0.001*\"p\"\n",
      "Topic: 3 \n",
      "Words: 0.002*\"estimate\" + 0.001*\"million\" + 0.001*\"inc\" + 0.001*\"rank\" + 0.001*\"week\" + 0.001*\"trade\" + 0.001*\"day\" + 0.001*\"p\" + 0.001*\"intel\" + 0.001*\"investment\"\n",
      "Topic: 4 \n",
      "Words: 0.002*\"estimate\" + 0.001*\"rank\" + 0.001*\"week\" + 0.001*\"inc\" + 0.001*\"p\" + 0.001*\"million\" + 0.001*\"investment\" + 0.001*\"day\" + 0.001*\"data\" + 0.001*\"industry\"\n",
      "Topic: 5 \n",
      "Words: 0.002*\"estimate\" + 0.001*\"rank\" + 0.001*\"million\" + 0.001*\"inc\" + 0.001*\"week\" + 0.001*\"investment\" + 0.001*\"p\" + 0.001*\"day\" + 0.001*\"industry\" + 0.001*\"data\"\n",
      "Topic: 6 \n",
      "Words: 0.001*\"estimate\" + 0.001*\"week\" + 0.001*\"million\" + 0.001*\"rank\" + 0.001*\"inc\" + 0.001*\"day\" + 0.001*\"investment\" + 0.001*\"trade\" + 0.001*\"p\" + 0.001*\"industry\"\n",
      "Topic: 7 \n",
      "Words: 0.001*\"estimate\" + 0.001*\"week\" + 0.001*\"day\" + 0.001*\"trade\" + 0.001*\"rank\" + 0.001*\"p\" + 0.001*\"million\" + 0.001*\"inc\" + 0.001*\"investment\" + 0.001*\"index\"\n",
      "Topic: 8 \n",
      "Words: 0.002*\"million\" + 0.001*\"rank\" + 0.001*\"estimate\" + 0.001*\"inc\" + 0.001*\"week\" + 0.001*\"day\" + 0.001*\"trade\" + 0.001*\"investment\" + 0.001*\"like\" + 0.001*\"p\"\n",
      "Topic: 9 \n",
      "Words: 0.002*\"estimate\" + 0.002*\"inc\" + 0.002*\"rank\" + 0.001*\"week\" + 0.001*\"day\" + 0.001*\"million\" + 0.001*\"trade\" + 0.001*\"p\" + 0.001*\"per\" + 0.001*\"index\"\n",
      "Topic: 10 \n",
      "Words: 0.002*\"estimate\" + 0.001*\"inc\" + 0.001*\"rank\" + 0.001*\"p\" + 0.001*\"week\" + 0.001*\"million\" + 0.001*\"investment\" + 0.001*\"trade\" + 0.001*\"day\" + 0.001*\"industry\"\n",
      "Topic: 11 \n",
      "Words: 0.002*\"estimate\" + 0.001*\"million\" + 0.001*\"rank\" + 0.001*\"inc\" + 0.001*\"week\" + 0.001*\"data\" + 0.001*\"investment\" + 0.001*\"day\" + 0.001*\"p\" + 0.001*\"trade\"\n",
      "Topic: 12 \n",
      "Words: 0.002*\"estimate\" + 0.001*\"rank\" + 0.001*\"inc\" + 0.001*\"data\" + 0.001*\"million\" + 0.001*\"week\" + 0.001*\"day\" + 0.001*\"p\" + 0.001*\"industry\" + 0.001*\"investment\"\n",
      "Topic: 13 \n",
      "Words: 0.002*\"estimate\" + 0.001*\"rank\" + 0.001*\"inc\" + 0.001*\"million\" + 0.001*\"week\" + 0.001*\"p\" + 0.001*\"data\" + 0.001*\"day\" + 0.001*\"trade\" + 0.001*\"investment\"\n",
      "Topic: 14 \n",
      "Words: 0.002*\"estimate\" + 0.001*\"million\" + 0.001*\"rank\" + 0.001*\"inc\" + 0.001*\"p\" + 0.001*\"week\" + 0.001*\"day\" + 0.001*\"trade\" + 0.001*\"investment\" + 0.001*\"data\"\n",
      "Topic: 15 \n",
      "Words: 0.001*\"estimate\" + 0.001*\"million\" + 0.001*\"week\" + 0.001*\"rank\" + 0.001*\"inc\" + 0.001*\"day\" + 0.001*\"p\" + 0.001*\"data\" + 0.001*\"trade\" + 0.001*\"investment\"\n",
      "Topic: 16 \n",
      "Words: 0.002*\"estimate\" + 0.001*\"week\" + 0.001*\"rank\" + 0.001*\"million\" + 0.001*\"day\" + 0.001*\"inc\" + 0.001*\"p\" + 0.001*\"chip\" + 0.001*\"data\" + 0.001*\"per\"\n",
      "Topic: 17 \n",
      "Words: 0.002*\"million\" + 0.001*\"estimate\" + 0.001*\"inc\" + 0.001*\"rank\" + 0.001*\"week\" + 0.001*\"day\" + 0.001*\"trade\" + 0.001*\"p\" + 0.001*\"data\" + 0.001*\"per\"\n",
      "Topic: 18 \n",
      "Words: 0.002*\"estimate\" + 0.002*\"rank\" + 0.001*\"million\" + 0.001*\"week\" + 0.001*\"day\" + 0.001*\"investment\" + 0.001*\"inc\" + 0.001*\"industry\" + 0.001*\"per\" + 0.001*\"data\"\n",
      "Topic: 19 \n",
      "Words: 0.002*\"estimate\" + 0.001*\"million\" + 0.001*\"rank\" + 0.001*\"inc\" + 0.001*\"week\" + 0.001*\"p\" + 0.001*\"day\" + 0.001*\"investment\" + 0.001*\"data\" + 0.001*\"like\"\n"
     ]
    }
   ],
   "source": [
    "# print topics\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: amount of documents per topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score:  0.2893881302419975\n"
     ]
    }
   ],
   "source": [
    "# coherence score\n",
    "coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, texts=df['lemmatized_content'], dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('Coherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Excitement is building up for the 2020 Summer Olympics in Tokyo as there is '\n",
      " 'more for tourists and locals to look forward to than just watching the world '\n",
      " 's best athletes excel in their game  Tokyo 2020 will not just be a sports '\n",
      " 'event but is set to amaze the world by showcasing the future of travel i e  '\n",
      " 'autonomous vehicles  The goal is to take advantage of the worldwide '\n",
      " 'attention to display innovative automotive industry technologies by Japan to '\n",
      " 'foster economic growth of the nation Driverless Cars on Tokyo Streets in '\n",
      " '2020Reportedly  the country will launch self driving vehicle services by '\n",
      " '2020  with around 100 autonomous vehicles roaming freely near the Olympics '\n",
      " 'venues  carrying up to 7 000 passengers in the week starting Jul 6  '\n",
      " 'Markedly  this will be Japan s biggest driverless vehicle trial to date  '\n",
      " 'exhibiting the country s strength in the nascent technology  The country  '\n",
      " 'which aims to put self driving cars on the market by 2025  will be running a '\n",
      " 'slew of tests on public roads in Tokyo till 2022  Japan s auto biggies like '\n",
      " 'Toyota Motor   NYSE TM   and Nissan Motor   OTC NSANY   along with local '\n",
      " 'parts manufacturers and startups will be participating in the event   While '\n",
      " 'Toyota has revealed its fleet of autonomous vehicles it plans to introduce '\n",
      " 'at Tokyo 2020  Nissan has not detailed its lineup  Both Toyota and Nissan '\n",
      " 'carry a Zacks Rank  3  Hold    You can see  Toyota s Olympics DreamToyota '\n",
      " 'intends to utilize its sponsorship of Tokyo 2020 to display its upgraded '\n",
      " 'technologies including zero emission transportation  robots  driverless '\n",
      " 'cars  accessible people mover  APM  Toyota will support Tokyo 2020 with APM '\n",
      " 'mobility vehicle set to run between venues for short distance trips  Japan s '\n",
      " 'biggest automaker will provide test drives of the Level 4 driverless cars  '\n",
      " 'with around 90  of its entire Olympic fleet electrified As part of its big '\n",
      " 'push toward robotaxis  Toyota will supply 20 of its e Palette electric '\n",
      " 'vehicles to serve the athletes  The vehicles will be controlled by a '\n",
      " 'specially designed automated driving system and will feature 3D mapping '\n",
      " 'technology along with an operation management system to offer automated '\n",
      " 'driving at SAE  society of automotive engineers  level 4  Notably  e Palette '\n",
      " 's specs and capabilities put it in the same ballpark as Waymo s current '\n",
      " 'fleet of driverless vehicles The automotive giant will also have a tiny '\n",
      " 'version of the e Palette  named Field Support Robot  to carry javelins  shot '\n",
      " 'puts and other items from throwing events  Apart from the javelin collecting '\n",
      " 'robot  Toyota s humanoid robot and a telepresence robot are also set for '\n",
      " 'Olympics debut  Another AI technology enabled  driverless vehicle  known as '\n",
      " 'Concept i  will travel alongside torch relay runners The Japanese auto giant '\n",
      " 'is working on  Chauffeur  software  which is focused on full autonomy  It is '\n",
      " 'also working on another system  Guardian   which is an advanced driver '\n",
      " 'assist system  similar to Tesla s   NASDAQ TSLA   Autopilot  Notably  last '\n",
      " 'year  the company inked a deal to invest  500 million in a self driving '\n",
      " 'project with Uber  NYSE UBER  on a fleet of autonomous Sienna minivans Japan '\n",
      " 'Aims to Step Up Autonomous Drive Push Despite being the leader in many '\n",
      " 'industrial fields  Japan s auto industry lags behind in the field of '\n",
      " 'autonomous driving compared with its U S  counterparts  Amid the lack of '\n",
      " 'sufficient regulatory and collaborative framework to develop self driving '\n",
      " 'infrastructure  Japan has failed to keep pace with the proactive involvement '\n",
      " 'of auto companies like Tesla  Daimler AG   OTC DDAIF    General Motors   '\n",
      " 'NYSE GM    Volkswagen  DE VOWG p  along with tech giants like Alphabet   '\n",
      " 'NASDAQ GOOGL    NVIDIA   NASDAQ NVDA    and Intel  NASDAQ INTC  among a few '\n",
      " 'others However  the market for driverless cars in Japan is set to grow '\n",
      " 'rapidly as rollouts shift into high gear next year  As the automotive '\n",
      " 'industry is a highly prioritized area for government and companies alike  '\n",
      " 'stakeholders are willingly embracing collaborations to develop next '\n",
      " 'generation vehicles  The development of proper regulations has gradually '\n",
      " 'started attracting worldwide technology providers who can test new '\n",
      " 'technologies without any concerns  Promoting the next generation '\n",
      " 'technologies will also prop up local jobs and help keep the country s '\n",
      " 'carmakers competitive overseas  Self driving vehicles are expected to become '\n",
      " 'immensely important in Japan in increasing traffic safety amid an aging '\n",
      " 'demography  Traffic accidents involving the elderly are on the rise in the '\n",
      " 'country and the implementation of next gen driverless cars will be a key '\n",
      " 'milestone  which would minimize road fatalities  The number of Advanced '\n",
      " 'Driver Assistance Systems  ADAS  units which are crucial for providing '\n",
      " 'safety and convivence to automated driving  has been on the rise  Japan s '\n",
      " 'emphasis on safety is expected to result in greater consumer acceptance of '\n",
      " 'driverless cars Final ThoughtsWe believe that the proper implementation of '\n",
      " 'government policies and adoption of technologies like artificial '\n",
      " 'intelligence  sensor fusion  V2X communication and Internet of Things among '\n",
      " 'others will aid Japan based carmakers to unleash the full potential of an '\n",
      " 'automated transportation system in the coming years  So  brace yourself as '\n",
      " 'the race to get driverless cars on the road will accelerate in the near '\n",
      " 'future Free  Zacks  Single Best Stock Set to Double Today you are invited to '\n",
      " 'download our latest Special Report that reveals 5 stocks with the most '\n",
      " 'potential to gain  100  or more in 2020  From those 5  Zacks Director of '\n",
      " 'Research  Sheraz Mian hand picks one to have the most explosive upside of '\n",
      " 'all This pioneering tech ticker had soared to all time highs and then '\n",
      " 'subsided to a price that is irresistible  Now a pending acquisition could '\n",
      " 'super charge the company s drive past competitors in the development of true '\n",
      " 'Artificial Intelligence  The earlier you get in to this stock  the greater '\n",
      " 'your potential gain ')\n"
     ]
    }
   ],
   "source": [
    "# pprint\n",
    "from pprint import pprint\n",
    "pprint(df['original_content'].iloc[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pyLDAvis' has no attribute 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# requires installing pyldavis\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# requires pandas version to 1.5.1\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyLDAvis\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m LDAvis_prepared \u001b[38;5;241m=\u001b[39m pyLDAvis\u001b[38;5;241m.\u001b[39mgensim\u001b[38;5;241m.\u001b[39mprepare(lda_model, bow, id2word)\n\u001b[0;32m      7\u001b[0m pyLDAvis\u001b[38;5;241m.\u001b[39msave_html(LDAvis_prepared, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./LDA_results/ldavis_prepared_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(n_topics) \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi3.html\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pyLDAvis' has no attribute 'gensim'"
     ]
    }
   ],
   "source": [
    "# requires installing pyldavis\n",
    "# requires pandas version to 1.5.1\n",
    "\n",
    "import pyLDAvis\n",
    "\n",
    "LDAvis_prepared = pyLDAvis.gensim.prepare(lda_model, bow, id2word)\n",
    "pyLDAvis.save_html(LDAvis_prepared, './LDA_results/ldavis_prepared_'+ str(n_topics) +'i3.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
